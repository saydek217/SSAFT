{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8490b8ef-bd13-4a22-8bff-808bbe2b2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "import numpy\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "from torch.utils import data\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_writer = SummaryWriter() #create the log_file \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b345948b-0aad-4e78-a0df-e9471faedf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(args, params, model=None):\n",
    "    filenames = []\n",
    "    \n",
    "    with open('../data/test.txt') as reader:\n",
    "        for filename in reader.readlines():\n",
    "            filename = filename.rstrip().split('/')[-1]\n",
    "            filenames.append('../data/new_data/test/' + filename)\n",
    "\n",
    "    dataset = Dataset(filenames, 640, params, False)\n",
    "    loader = data.DataLoader(dataset, 8, False, num_workers=8,\n",
    "                             pin_memory=True, collate_fn=Dataset.collate_fn)\n",
    "\n",
    "    if model is None:\n",
    "        model = torch.load('./weights/best.pt', map_location='cuda')['model'].float()\n",
    "\n",
    "    model.half()\n",
    "    model.eval()\n",
    "    # Configure\n",
    "    iou_v = torch.linspace(0.5, 0.95, 10).cuda()  # iou vector for mAP@0.5:0.95\n",
    "    n_iou = iou_v.numel()\n",
    "\n",
    "    m_pre = 0.\n",
    "    m_rec = 0.\n",
    "    map50 = 0.\n",
    "    mean_ap = 0.\n",
    "    metrics = []\n",
    "    p_bar = tqdm.tqdm(loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n",
    "    for samples, targets, shapes in p_bar:\n",
    "        samples = samples.cuda()\n",
    "        targets = targets.cuda()\n",
    "        samples = samples.half()  # uint8 to fp16/32\n",
    "        samples = samples / 255  # 0 - 255 to 0.0 - 1.0\n",
    "        _, _, height, width = samples.shape  # batch size, channels, height, width\n",
    "\n",
    "        # Inference\n",
    "        outputs = model(samples)\n",
    "        # NMS\n",
    "        targets[:, 2:] *= torch.tensor((width, height, width, height)).cuda()  # to pixels\n",
    "        outputs = util.non_max_suppression(outputs, 0.001, 0.65)\n",
    "\n",
    "        # Metrics\n",
    "        for i, output in enumerate(outputs):\n",
    "            labels = targets[targets[:, 0] == i, 1:]\n",
    "            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).cuda()\n",
    "\n",
    "            if output.shape[0] == 0:\n",
    "                if labels.shape[0]:\n",
    "                    metrics.append((correct, *torch.zeros((3, 0)).cuda()))\n",
    "                continue\n",
    "\n",
    "            detections = output.clone()\n",
    "            util.scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "            # Evaluate\n",
    "            if labels.shape[0]:\n",
    "                tbox = labels[:, 1:5].clone()  # target boxes\n",
    "                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n",
    "                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n",
    "                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n",
    "                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n",
    "                util.scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "                correct = numpy.zeros((detections.shape[0], iou_v.shape[0]))\n",
    "                correct = correct.astype(bool)\n",
    "\n",
    "                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n",
    "                iou = util.box_iou(t_tensor[:, 1:], detections[:, :4])\n",
    "                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n",
    "                for j in range(len(iou_v)):\n",
    "                    x = torch.where((iou >= iou_v[j]) & correct_class)\n",
    "                    if x[0].shape[0]:\n",
    "                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n",
    "                        matches = matches.cpu().numpy()\n",
    "                        if x[0].shape[0] > 1:\n",
    "                            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                            matches = matches[numpy.unique(matches[:, 1], return_index=True)[1]]\n",
    "                            matches = matches[numpy.unique(matches[:, 0], return_index=True)[1]]\n",
    "                        correct[matches[:, 1].astype(int), j] = True\n",
    "                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n",
    "            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n",
    "    if len(metrics) and metrics[0].any():\n",
    "        tp, fp, m_pre, m_rec, map50, mean_ap = util.compute_ap(*metrics)\n",
    "\n",
    "    # Print results\n",
    "    print('%10.3g' * 3 % (m_pre, m_rec, mean_ap))\n",
    "\n",
    "    # Return results\n",
    "    model.float()  # for training\n",
    "    return map50, mean_ap, m_pre, m_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef0304b-ba70-44f7-a9dd-ffa267b5bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'input_size': 640,\n",
    "    'batch_size': 16,\n",
    "    'local_rank': 0,  # This might be irrelevant in a non-distributed setup\n",
    "    'epochs': 1,\n",
    "    'train': True,  # Set to False if you don't want to train\n",
    "    'test': False,  # Set to True if you want to test\n",
    "    'world_size': 1 # Assuming a single-process setup\n",
    "}\n",
    "\n",
    "# Adjust for potential distributed computing environments, even though it might not be applicable\n",
    "args['local_rank'] = int(os.getenv('LOCAL_RANK', 0))\n",
    "args['world_size'] = int(os.getenv('WORLD_SIZE', 1))\n",
    "\n",
    "if args['world_size'] > 1:\n",
    "    torch.cuda.set_device(device=args['local_rank'])\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "\n",
    "if args['local_rank'] == 0:\n",
    "    if not os.path.exists('weights'):\n",
    "        os.makedirs('weights')\n",
    "\n",
    "# Assuming util is a module with these functions. If not, you'll need to define them or adjust accordingly.\n",
    "util.setup_seed()\n",
    "util.setup_multi_processes()\n",
    "\n",
    "# Load parameters from args.yaml\n",
    "with open('./utils/args_indoor_openImages.yaml', 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "args_namespace = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0eece7f-1225-42da-be1c-005a3b60e092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " precision    recall       mAP:   0%|                                                         | 0/2067 [00:00<?, ?it/s]C:\\Users\\SalahEddine.Laidoudi\\miniconda3\\envs\\ultra\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " precision    recall       mAP: 100%|██████████████████████████████████████████████| 2067/2067 [05:56<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.625     0.516     0.384\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m ema \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mEMA(model)\n\u001b[0;32m      4\u001b[0m last \u001b[38;5;241m=\u001b[39m test(args, params, ema\u001b[38;5;241m.\u001b[39mema)\n\u001b[1;32m----> 5\u001b[0m tb_writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP\u001b[39m\u001b[38;5;124m'\u001b[39m, last[\u001b[38;5;241m1\u001b[39m], global_step\u001b[38;5;241m=\u001b[39m\u001b[43mepoch\u001b[49m)\n\u001b[0;32m      6\u001b[0m tb_writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@50\u001b[39m\u001b[38;5;124m'\u001b[39m, last[\u001b[38;5;241m0\u001b[39m], global_step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m      7\u001b[0m tb_writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m, last[\u001b[38;5;241m2\u001b[39m], global_step\u001b[38;5;241m=\u001b[39mepoch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "model = torch.load('./weights/BESTLastlayerTransformerwithDarkfpn320epochs.pt', map_location='cuda')['model'].float()\n",
    "ema = util.EMA(model)\n",
    "\n",
    "last = test(args, params, ema.ema)\n",
    "tb_writer.add_scalar('mAP', last[1], global_step=epoch)\n",
    "tb_writer.add_scalar('mAP@50', last[0], global_step=epoch)\n",
    "tb_writer.add_scalar('Precision', last[2], global_step=epoch)\n",
    "tb_writer.add_scalar('recall', last[3], global_step=epoch)\n",
    "writer.writerow({'mAP': str(f'{last[1]:.3f}'),\n",
    "                 'epoch': str(epoch + 1).zfill(3),\n",
    "                 'mAP@50': str(f'{last[0]:.3f}')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037b7f-2426-49be-af3a-84ac64bd989b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra",
   "language": "python",
   "name": "ultra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
